# -*- coding: utf-8 -*-
"""Thesis Methodology: Scalable Soccer Analytics with PySpark.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GWCG-u-057JKMiDKGjfZrtaCuAID_gN6

Install PySpark and Setup
"""



"""**Initialize PySpark and Show Methodology**"""

from pyspark.sql import SparkSession
from pyspark.sql.functions import *
from pyspark.sql.types import *
from pyspark.ml.feature import VectorAssembler, StringIndexer
from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml import Pipeline
import pandas as pd

# Initialize Spark Session - THIS WILL WORK IN COLAB!
spark = SparkSession.builder \
    .appName("SoccerAnalyticsThesis") \
    .getOrCreate()

print("âœ… PySpark INITIALIZED SUCCESSFULLY!")
print("ðŸ”¬ BIG DATA FRAMEWORK READY FOR RESEARCH")
print("=" * 60)

"""**Create Sample Soccer Dataset**"""

# METHODOLOGY: Data Collection & Preparation
print("ðŸ“Š CREATING SAMPLE SOCCER DATASET...")

sample_data = [
    # shot_id, player, team, x_coord, y_coord, situation, body_part, minute, is_goal
    ("s1", "Player_A", "Team_A", 85.0, 25.0, "OpenPlay", "RightFoot", 23, 1),
    ("s2", "Player_B", "Team_B", 92.0, 40.0, "OpenPlay", "RightFoot", 45, 0),
    ("s3", "Player_A", "Team_A", 98.0, 48.0, "Penalty", "RightFoot", 67, 1),
    ("s4", "Player_C", "Team_C", 75.0, 15.0, "OpenPlay", "RightFoot", 12, 0),
    ("s5", "Player_B", "Team_B", 88.0, 35.0, "SetPiece", "Head", 34, 0),
    ("s6", "Player_C", "Team_C", 95.0, 45.0, "OpenPlay", "RightFoot", 78, 1),
    ("s7", "Player_A", "Team_A", 84.0, 22.0, "OpenPlay", "LeftFoot", 56, 1),
    ("s8", "Player_B", "Team_B", 90.0, 42.0, "SetPiece", "RightFoot", 29, 0),
    ("s9", "Player_C", "Team_C", 97.0, 47.0, "Penalty", "RightFoot", 81, 1),
    ("s10", "Player_A", "Team_A", 82.0, 28.0, "OpenPlay", "RightFoot", 15, 0)
]

schema = StructType([
    StructField("shot_id", StringType(), True),
    StructField("player", StringType(), True),
    StructField("team", StringType(), True),
    StructField("x_coord", DoubleType(), True),
    StructField("y_coord", DoubleType(), True),
    StructField("situation", StringType(), True),
    StructField("body_part", StringType(), True),
    StructField("minute", IntegerType(), True),
    StructField("is_goal", IntegerType(), True)
])

shots_df = spark.createDataFrame(sample_data, schema)

print("âœ… SAMPLE SOCCER DATASET CREATED")
print("ðŸ“ˆ DATA SCALE: 10 shots (demonstrating scalable approach)")
shots_df.show()

"""**Feature Engineering Methodology**"""

# METHODOLOGY: Domain-Specific Feature Engineering
print("ðŸ”¬ METHODOLOGY 1: SOCCER INTELLIGENCE FEATURE ENGINEERING")

# Calculate advanced soccer metrics
engineered_data = shots_df \
    .withColumn("distance_to_goal",
               sqrt(pow((100 - col("x_coord")), 2) + pow((50 - col("y_coord")), 2))) \
    .withColumn("angle_to_goal",
               degrees(asin((abs(50 - col("y_coord"))) / col("distance_to_goal")))) \
    .withColumn("is_penalty", when(col("situation") == "Penalty", 1).otherwise(0)) \
    .withColumn("is_set_piece", when(col("situation") == "SetPiece", 1).otherwise(0)) \
    .withColumn("is_head", when(col("body_part") == "Head", 1).otherwise(0)) \
    .withColumn("game_period",
               when(col("minute") <= 30, "First")
               .when(col("minute") <= 60, "Second")
               .otherwise("Final"))

print("âœ… ENGINEERED FEATURES:")
print("   - distance_to_goal: Spatial analysis")
print("   - angle_to_goal: Geometric probability")
print("   - game_situation_flags: Contextual intelligence")
print("   - temporal_features: Game period analysis")

engineered_data.select("shot_id", "player", "distance_to_goal", "angle_to_goal",
                      "is_penalty", "is_goal").show()

"""**Assumption Checking**"""

print("ðŸ” METHODOLOGY: CHECKING DATA CONDITIONS & ASSUMPTIONS")

# 1. Check class balance (is_goal)
engineered_data.groupBy("is_goal").count().show()

# 2. Check for missing values in key columns
from pyspark.sql.functions import sum as spark_sum

cols_to_check = ["x_coord", "y_coord", "situation", "body_part",
                 "distance_to_goal", "angle_to_goal", "is_goal"]
missing_exprs = [spark_sum(col(c).isNull().cast("int")).alias(c) for c in cols_to_check]
engineered_data.agg(*missing_exprs).show()

# 3. Basic descriptive stats for numeric features
engineered_data.select("x_coord", "y_coord", "distance_to_goal", "angle_to_goal", "minute").describe().show()

print("âœ… ASSUMPTION CHECK SUMMARY:")
print("   - No missing values in key features (synthetic data).")
print("   - Feature ranges are realistic for soccer pitch coordinates.")
print("   - Observations are treated as independent (shot-level model).")
print("   - Class balance will need to be revisited on the real dataset.")
print("   - The same checks will be repeated on the real data before final model estimation.")

"""**Machine Learning Pipeline**"""

# METHODOLOGY 2: Production ML Pipeline
print("ðŸ”¬ METHODOLOGY 2: MACHINE LEARNING PIPELINE DEVELOPMENT")

# Data preprocessing
situation_indexer = StringIndexer(inputCol="situation", outputCol="situation_idx")
body_part_indexer = StringIndexer(inputCol="body_part", outputCol="body_part_idx")
game_period_indexer = StringIndexer(inputCol="game_period", outputCol="game_period_idx")

# Feature assembly
feature_columns = ["distance_to_goal", "angle_to_goal", "is_penalty", "is_set_piece",
                   "is_head", "situation_idx", "body_part_idx", "game_period_idx"]

assembler = VectorAssembler(inputCols=feature_columns, outputCol="features")

# Model definition
rf = RandomForestClassifier(
    featuresCol="features",
    labelCol="is_goal",
    numTrees=50,
    maxDepth=5,
    seed=42
)

# Create end-to-end pipeline
pipeline = Pipeline(stages=[
    situation_indexer,
    body_part_indexer,
    game_period_indexer,
    assembler,
    rf
])

print("âœ… ML PIPELINE COMPONENTS:")
print("   - StringIndexer: Categorical data processing")
print("   - VectorAssembler: Feature vector creation")
print("   - RandomForest: Ensemble learning model")
print("   - Pipeline: Reproducible workflow")

print("ðŸ”§ PIPELINE STRUCTURE BUILT - READY FOR TRAINING")

"""**Trainâ€“Test Split**"""

# METHODOLOGY 3: Trainâ€“Test Split for Fair Evaluation
print("ðŸ”€ METHODOLOGY 3: TRAINâ€“TEST SPLIT")

train_df, test_df = engineered_data.randomSplit([0.7, 0.3], seed=42)

print(f"   - Training samples: {train_df.count()}")
print(f"   - Test samples:     {test_df.count()}")
print("âœ… Data split into training and test sets.")

""" **Model** **Training** **&** **Evaluation**"""

# METHODOLOGY 3: Model Training and Evaluation
print("ðŸ”¬ METHODOLOGY 3: MODEL TRAINING & STATISTICAL EVALUATION (TEST-SET BASED)")

# Train the model on TRAINING set
model = pipeline.fit(train_df)
print("âœ… MODEL TRAINING COMPLETED on training set")

# Generate predictions on TEST set
predictions = model.transform(test_df)
print("âœ… PREDICTIONS GENERATED on test set")

# Show sample predictions
predictions.select(
    "shot_id", "player", "is_goal", "prediction", "probability"
).show(truncate=False)

# Evaluation using AUC on TEST set
from pyspark.ml.evaluation import BinaryClassificationEvaluator

evaluator = BinaryClassificationEvaluator(
    labelCol="is_goal",
    rawPredictionCol="rawPrediction",
    metricName="areaUnderROC"
)

try:
    auc = evaluator.evaluate(predictions)
    print(f"ðŸ“Š MODEL PERFORMANCE (Random Forest, TEST SET AUC) = {auc:.4f}")
    print("ðŸ§  INTERPRETATION:")
    print("   - AUC is computed on a held-out test set, so it reflects generalization")
    print("     performance of the xG model rather than just memorizing the training data.")
    print("   - In the full thesis, the same evaluation setup will be applied to the real,")
    print("     large-scale event data to compare different model variants.")
except Exception as e:
    print("ðŸ“Š MODEL PERFORMANCE: Evaluation could not be computed on this small synthetic sample.")
    print("   Error:", str(e))

print("ðŸŽ¯ RESEARCH OUTCOME: Expected Goals (xG) model prototype trained and evaluated on synthetic data.")

"""**Feature Importance (Interpretability)**"""

# METHODOLOGY 4: Model Interpretability â€“ Feature Importances
print("\nðŸ“Œ METHODOLOGY 4: FEATURE IMPORTANCE ANALYSIS (Random Forest)")

# Extract the Random Forest stage from the pipeline
rf_stage = model.stages[-1]
importances = rf_stage.featureImportances.toArray()

# Pair feature names with their importance values
feature_importance = list(zip(feature_columns, importances))
feature_importance_sorted = sorted(feature_importance, key=lambda x: x[1], reverse=True)

print("ðŸ” Feature Importances (sorted):")
for feat, imp in feature_importance_sorted:
    print(f"   - {feat}: {imp:.4f}")

print("\nðŸ§  INTERPRETATION (Feature Importance):")
print("   - Features with higher scores contribute more to predicting goal probability.")
print("   - This helps understand which aspects (distance, angle, shot context) matter most.")
print("   - In the real dataset, this becomes part of the tactical decision-making insight.")

"""**Logistic Regression Variant (Method Extension)**"""

from pyspark.ml.classification import LogisticRegression

# METHODOLOGY 5: Variant â€“ Logistic Regression Baseline
print("\nðŸ§ª METHODOLOGY 5: BASELINE LOGISTIC REGRESSION VS RANDOM FOREST")

# Define Logistic Regression model
lr = LogisticRegression(
    featuresCol="features",
    labelCol="is_goal",
    maxIter=50,
    regParam=0.01
)

# Build pipeline for Logistic Regression (same preprocessing steps)
lr_pipeline = Pipeline(stages=[
    situation_indexer,
    body_part_indexer,
    game_period_indexer,
    assembler,
    lr
])

print("ðŸ”§ Logistic Regression pipeline built.")

# Train the logistic regression model
lr_model = lr_pipeline.fit(train_df)
print("âœ… Logistic Regression trained on training set")

# Predict on test set
lr_predictions = lr_model.transform(test_df)

# Evaluate LR using AUC
lr_auc = evaluator.evaluate(lr_predictions)

print(f"ðŸ“Š LOGISTIC REGRESSION - TEST SET AUC: {lr_auc:.4f}")
print(f"ðŸ“Š RANDOM FOREST       - TEST SET AUC: {auc:.4f}")

print("\nðŸ§  INTERPRETATION (Model Variant):")
print("   - Logistic Regression provides a simpler, linear baseline model for xG.")
print("   - Random Forest captures non-linear interactions between features.")
print("   - This comparison demonstrates methodological rigor and supports model selection.")

"""**Research Methodology Summary**"""

# METHODOLOGY 4: Academic Research Framework
print("ðŸ“š THESIS METHODOLOGY SUMMARY")
print("=" * 60)

research_methodologies = [
    ("BIG DATA PROCESSING", "PySpark for scalable sports data handling"),
    ("FEATURE ENGINEERING", "Domain-specific soccer intelligence metrics"),
    ("ML PIPELINE DEVELOPMENT", "End-to-end model training framework"),
    ("MODEL EVALUATION", "Statistical validation and performance metrics"),
    ("SCALABLE ARCHITECTURE", "Designed for large-scale multi-season data"),
    ("RESEARCH REPRODUCIBILITY", "Version-controlled, documented methodology")
]

for i, (methodology, description) in enumerate(research_methodologies, 1):
    print(f"{i}. {methodology}:")
    print(f"   {description}")

print("\nðŸŽ“ THESIS: 'Design and Implementation of a Scalable Big Data Platform for Soccer Analytics'")
print("âœ… ALL METHODOLOGIES SUCCESSFULLY DEMONSTRATED")
print("ðŸ”œ NEXT: Full implementation with real soccer data")

# Performance metrics summary
print(f"\nðŸ“ˆ DEMONSTRATION METRICS:")
print(f"   - Data Points Processed: {predictions.count()}")
print(f"   - Features Engineered: {len(feature_columns)}")
print(f"   - ML Pipeline Components: {len(pipeline.getStages())}")
print(f"   - Framework: PySpark (Big Data Ready)")

spark.stop()
print("\nâœ… PySpark Session Closed - Demonstration Complete")